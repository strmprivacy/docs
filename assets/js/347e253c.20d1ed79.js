"use strict";(self.webpackChunkend_user_docs=self.webpackChunkend_user_docs||[]).push([[9347],{3905:(e,t,n)=>{n.d(t,{Zo:()=>l,kt:()=>u});var a=n(7294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var c=a.createContext({}),p=function(e){var t=a.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},l=function(e){var t=p(e.components);return a.createElement(c.Provider,{value:t},e.children)},h={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,r=e.originalType,c=e.parentName,l=i(e,["components","mdxType","originalType","parentName"]),d=p(n),u=o,m=d["".concat(c,".").concat(u)]||d[u]||h[u]||r;return n?a.createElement(m,s(s({ref:t},l),{},{components:n})):a.createElement(m,s({ref:t},l))}));function u(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=n.length,s=new Array(r);s[0]=d;var i={};for(var c in t)hasOwnProperty.call(t,c)&&(i[c]=t[c]);i.originalType=e,i.mdxType="string"==typeof e?e:o,s[1]=i;for(var p=2;p<r;p++)s[p]=n[p];return a.createElement.apply(null,s)}return a.createElement.apply(null,n)}d.displayName="MDXCreateElement"},9325:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>s,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>p});var a=n(7462),o=(n(7294),n(3905));const r={title:"Batch Jobs",hide_table_of_contents:!1},s=void 0,i={unversionedId:"concepts/data-processing/batch-jobs",id:"concepts/data-processing/batch-jobs",title:"Batch Jobs",description:"[purpose-maps]: docs/02-concepts/06-purpose-maps.md",source:"@site/docs/02-concepts/01-data-processing/04-batch-jobs.md",sourceDirName:"02-concepts/01-data-processing",slug:"/concepts/data-processing/batch-jobs",permalink:"/docs/latest/concepts/data-processing/batch-jobs",draft:!1,tags:[],version:"current",sidebarPosition:4,frontMatter:{title:"Batch Jobs",hide_table_of_contents:!1},sidebar:"docs",previous:{title:"Data Pipelines",permalink:"/docs/latest/concepts/data-processing/data-pipelines"},next:{title:"Policies",permalink:"/docs/latest/concepts/data-processing/policies"}},c={},p=[{value:"Encryption keys",id:"encryption-keys",level:2},{value:"The importance of timestamps",id:"the-importance-of-timestamps",level:2},{value:"Batch Job Groups",id:"batch-job-groups",level:2}],l={toc:p};function h(e){let{components:t,...n}=e;return(0,o.kt)("wrapper",(0,a.Z)({},l,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"With the differences between ",(0,o.kt)("a",{parentName:"p",href:"/docs/latest/concepts/data-processing/batch-vs-streaming"},"Batch and Stream")," processing covered,\nyou have already encountered Batch Jobs. This article covers how batch jobs work."),(0,o.kt)("h1",{id:"batch-job-concepts"},"Batch Job Concepts"),(0,o.kt)("p",null,"STRM Privacy supports batch processing through Batch Jobs. A Batch Job\nrepresents the processing of one file: encryption, decryption,\nmasking and exporting the results. This means that a Batch Job has a\nfinite lifetime after it starts. It either succeeds or it fails, it\u2019s\nnot a continuously running process, unlike a Kafka Consumer or a Batch\nExporter."),(0,o.kt)("p",null,"Processing multiple files thus requires multiple Batch Jobs and a Batch\nJob cannot be reinstantiated for a second run."),(0,o.kt)("admonition",{type:"note"},(0,o.kt)("p",{parentName:"admonition"},"Batch Jobs currently support one file per job, but could be extended to support multiple files per job.\nPlease ",(0,o.kt)("a",{parentName:"p",href:"/docs/latest/contact/"},"contact us")," if you are interested in this.")),(0,o.kt)("h1",{id:"encryption"},"Encryption"),(0,o.kt)("p",null,"A lot in STRM Privacy data processing, both batch and streaming, revolves around\nencryption of data. While most of it is the same, there are subtle\ndifferences between how data is encrypted between the two, mostly\nrelated to timing."),(0,o.kt)("h2",{id:"encryption-keys"},"Encryption keys"),(0,o.kt)("p",null,"When using streams, encryption keys are generated on-the-fly when there\nis no existing key for the given key field value. These encryption keys\nthen have a ",(0,o.kt)("a",{parentName:"p",href:"/docs/latest/concepts/data-processing/pii-field-encryption#algorithm"},"lifetime of 24 hours"),", after which a new encryption key is\ngenerated when an event comes in. So this process relies on the current time."),(0,o.kt)("p",null,"When relying on the current time while processing a batch of data, two\nthings can happen:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"A big batch of data contains records that are more than 24 hours\napart. This causes too much data to be encrypted using the same\nencryption key, which is undesirable.")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},'A batch contains data with records that are less than 24 hours\napart. This causes encryption keys to be rotated too often, making\nit hard to "link" associated data, like a user session.'))),(0,o.kt)("admonition",{type:"info"},(0,o.kt)("p",{parentName:"admonition"},"These two statements assume that a Batch Job takes less than 24 hours,\nwhich is the common case and thus a valid assumption.")),(0,o.kt)("admonition",{type:"note"},(0,o.kt)("p",{parentName:"admonition"},"In either case, the current time is not usable with batch processing.")),(0,o.kt)("h2",{id:"the-importance-of-timestamps"},"The importance of timestamps"),(0,o.kt)("p",null,"Because we cannot use the current time, and the timestamp is mandatory,\nwe require a timestamp to be present in every record."),(0,o.kt)("p",null,"This timestamp can then be used to determine which encryption key is\nused when encrypting the PII fields in this record."),(0,o.kt)("p",null,"For determining the encryption key, we persistently store all encryption\nkeys in a database, along with a time window in which the key is valid.\nJust as with streaming, this window is 24 hours."),(0,o.kt)("admonition",{type:"info"},(0,o.kt)("p",{parentName:"admonition"},"Persisting encryption keys is a crucial responsibility. What needs to happen with the encryption keys,\nafter batch jobs have been executed greatly depends on the use case. Currently, no APIs exist that allow\nfor the management of the encryption keys. Please ",(0,o.kt)("a",{parentName:"p",href:"/docs/latest/contact/"},"contact us")," if you are\ninterested in this.")),(0,o.kt)("h2",{id:"batch-job-groups"},"Batch Job Groups"),(0,o.kt)("p",null,"Batch Jobs can be configured to be part of the same ",(0,o.kt)("em",{parentName:"p"},"group"),". This means\nthat these Batch Jobs use the same set of encryption keys. This can be\nvery helpful when the same dataset is split across multiple files and/or\nyou\u2019d like to have a fluent transition at time window boundaries."),(0,o.kt)("h1",{id:"data-connectors"},"Data Connectors"),(0,o.kt)("p",null,"A Batch Job reads data from and sends data to a ",(0,o.kt)("a",{parentName:"p",href:"/docs/latest/concepts/data-connectors"},"Data Connector"),",\nwhich provides read and/or write access to e.g. an AWS S3 or GCS bucket."),(0,o.kt)("p",null,"For a Batch Job, three or more Data Connectors need to be specified,\nfor:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Location of the source data"),". from which location is the unencrypted/raw data read?"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Location of the encrypted data"),". where will the encrypted data be stored?"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Location of the encryption keys"),". where will the encrypted keys be stored?"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Zero or more locations for the derived data"),". where will every file with derived data be stored?")),(0,o.kt)("p",null,"Having separate Data Connectors for each piece of input/output data\nmakes it possible to create data pipelines that are inherently safe,\nbecause consumers only see the data they\u2019re allowed to see. But of\ncourse it\u2019s also possible to reuse the same Data Connector."),(0,o.kt)("h1",{id:"consent"},"Consent"),(0,o.kt)("p",null,"Just like with stream processing, a lot of data processing relies on consent; the\nconsent of the data subject (i.e. the visitor on the website) and the\nconsent that needs to be decrypted."),(0,o.kt)("p",null,"For this, every record or event needs to have the consent of the end\nuser. Without consent, only encrypted PII fields can be used (",(0,o.kt)("em",{parentName:"p"},"missing consent")," equals ",(0,o.kt)("em",{parentName:"p"},"no consent"),")."),(0,o.kt)("p",null,"To fit into as many environments as possible, a mechanism is provided to\nextract the consent from the source data:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"Specify the field that contains the consent"),(0,o.kt)("li",{parentName:"ol"},"Specify a mapping to translate your terminology to purposes from your ",(0,o.kt)("a",{parentName:"li",href:"/docs/latest/concepts/purpose-maps"},"purpose maps"),'.\nList the integer value(s) ("levels") of the applicable purpose(s) for which consent should be considered provided.\nA mapping in pseudo-code could be:',(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},"functional -> [0]\npersonalized-ads -> [1]\nanalytics -> [1,2]\nmarketing -> [1,2,3]\n"))),(0,o.kt)("li",{parentName:"ol"},"If no mapping is specified, an attempt is made to parse the data as an integer\narray, as follows: ",(0,o.kt)("inlineCode",{parentName:"li"},'"\\[1,2\\]"')," or as an int, as follows: ",(0,o.kt)("inlineCode",{parentName:"li"},'"1"'),"."),(0,o.kt)("li",{parentName:"ol"},"If no mapping is specified, and the data is not an integer or integer array, or if\nthere is another error while parsing, the provided default is used.\nTypically, this is an empty list, meaning ",(0,o.kt)("em",{parentName:"li"},"no consent")," or ",(0,o.kt)("em",{parentName:"li"},"unknown"),".")),(0,o.kt)("admonition",{type:"note"},(0,o.kt)("p",{parentName:"admonition"},"There are more ways to extract consent than a fixed mapping, like User Defined Functions (UDFs). This is not planned\nin the near future, but please ",(0,o.kt)("a",{parentName:"p",href:"/docs/latest/contact/"},"contact us")," if you are interested in this.")),(0,o.kt)("h1",{id:"batch-job-states"},"Batch Job states"),(0,o.kt)("p",null,"Batch Jobs progress through a series of states in case of success:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"The Batch Job has a finite lifetime. When created, it has the\nstatus: ",(0,o.kt)("inlineCode",{parentName:"li"},"PENDING"),". This means it has been successfully created and\nwill be started soon."),(0,o.kt)("li",{parentName:"ol"},"When the Batch Job is started it gets the status: ",(0,o.kt)("inlineCode",{parentName:"li"},"STARTED"),". This\nmeans all Data Connectors have been initialized, and it is about to\nread the source data."),(0,o.kt)("li",{parentName:"ol"},"While the Batch Job is running, it has the status: ",(0,o.kt)("inlineCode",{parentName:"li"},"RUNNING")," every\n10 seconds."),(0,o.kt)("li",{parentName:"ol"},"When it\u2019s done and all files have been uploaded to the respective\nData Connectors, it has the status ",(0,o.kt)("inlineCode",{parentName:"li"},"FINISHED"),".")),(0,o.kt)("p",null,"In case of errors, Batch Jobs progress through the following states:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"When there is an error starting the Batch Job, it gets the status:\n",(0,o.kt)("inlineCode",{parentName:"li"},"ERROR_STARTING"),". We retry restarting it for three times, after\nwhich we consider it an unrecoverable error, and we stop trying."),(0,o.kt)("li",{parentName:"ol"},"When there is an error while running the Batch Job, for example,\nwhile processing a CSV or writing to a Data Connector, it gets the\nstatus: ",(0,o.kt)("inlineCode",{parentName:"li"},"ERROR"),". We consider this an unrecoverable error, and we\ndon\u2019t retry.")))}h.isMDXComponent=!0}}]);